---
name: kubernetes-apps
interval: 0s
rules:
- record: ""
  alert: KubePodCrashLooping
  expr: |
    max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="integrations/kubernetes/kube-state-metrics"}[5m]) >= 1
  for: 15m
  labels:
    severity: warning
  annotations:
    description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff").'
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
    summary: Pod is crash looping.
- record: ""
  alert: KubePodNotReady
  expr: |
    sum by (namespace, pod) (
      max by(namespace, pod) (
        kube_pod_status_phase{job="integrations/kubernetes/kube-state-metrics", phase=~"Pending|Unknown"}
      ) * on(namespace, pod) group_left(owner_kind) topk by(namespace, pod) (
        1, max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!="Job"})
      )
    ) > 0
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready
    summary: Pod has been in a non-ready state for more than 15 minutes.
- record: ""
  alert: KubeDeploymentGenerationMismatch
  expr: |
    kube_deployment_status_observed_generation{job="integrations/kubernetes/kube-state-metrics"}
      !=
    kube_deployment_metadata_generation{job="integrations/kubernetes/kube-state-metrics"}
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch
    summary: Deployment generation mismatch due to possible roll-back
- record: ""
  alert: KubeDeploymentReplicasMismatch
  expr: |
    (
      kube_deployment_spec_replicas{job="integrations/kubernetes/kube-state-metrics"}
        >
      kube_deployment_status_replicas_available{job="integrations/kubernetes/kube-state-metrics"}
    ) and (
      changes(kube_deployment_status_replicas_updated{job="integrations/kubernetes/kube-state-metrics"}[10m])
        ==
      0
    )
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch
    summary: Deployment has not matched the expected number of replicas.
- record: ""
  alert: KubeStatefulSetReplicasMismatch
  expr: |
    (
      kube_statefulset_status_replicas_ready{job="integrations/kubernetes/kube-state-metrics"}
        !=
      kube_statefulset_status_replicas{job="integrations/kubernetes/kube-state-metrics"}
    ) and (
      changes(kube_statefulset_status_replicas_updated{job="integrations/kubernetes/kube-state-metrics"}[10m])
        ==
      0
    )
  for: 15m
  labels:
    severity: warning
  annotations:
    description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch
    summary: Deployment has not matched the expected number of replicas.
- record: ""
  alert: KubeStatefulSetGenerationMismatch
  expr: |
    kube_statefulset_status_observed_generation{job="integrations/kubernetes/kube-state-metrics"}
      !=
    kube_statefulset_metadata_generation{job="integrations/kubernetes/kube-state-metrics"}
  for: 15m
  labels:
    severity: warning
  annotations:
    description: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch
    summary: StatefulSet generation mismatch due to possible roll-back
- record: ""
  alert: KubeStatefulSetUpdateNotRolledOut
  expr: |
    (
      max without (revision) (
        kube_statefulset_status_current_revision{job="integrations/kubernetes/kube-state-metrics"}
          unless
        kube_statefulset_status_update_revision{job="integrations/kubernetes/kube-state-metrics"}
      )
        *
      (
        kube_statefulset_replicas{job="integrations/kubernetes/kube-state-metrics"}
          !=
        kube_statefulset_status_replicas_updated{job="integrations/kubernetes/kube-state-metrics"}
      )
    )  and (
      changes(kube_statefulset_status_replicas_updated{job="integrations/kubernetes/kube-state-metrics"}[5m])
        ==
      0
    )
  for: 15m
  labels:
    severity: warning
  annotations:
    description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout
    summary: StatefulSet update has not been rolled out.
- record: ""
  alert: KubeDaemonSetRolloutStuck
  expr: |
    (
      (
        kube_daemonset_status_current_number_scheduled{job="integrations/kubernetes/kube-state-metrics"}
         !=
        kube_daemonset_status_desired_number_scheduled{job="integrations/kubernetes/kube-state-metrics"}
      ) or (
        kube_daemonset_status_number_misscheduled{job="integrations/kubernetes/kube-state-metrics"}
         !=
        0
      ) or (
        kube_daemonset_updated_number_scheduled{job="integrations/kubernetes/kube-state-metrics"}
         !=
        kube_daemonset_status_desired_number_scheduled{job="integrations/kubernetes/kube-state-metrics"}
      ) or (
        kube_daemonset_status_number_available{job="integrations/kubernetes/kube-state-metrics"}
         !=
        kube_daemonset_status_desired_number_scheduled{job="integrations/kubernetes/kube-state-metrics"}
      )
    ) and (
      changes(kube_daemonset_updated_number_scheduled{job="integrations/kubernetes/kube-state-metrics"}[5m])
        ==
      0
    )
  for: 15m
  labels:
    severity: warning
  annotations:
    description: DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15 minutes.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck
    summary: DaemonSet rollout is stuck.
- record: ""
  alert: KubeContainerWaiting
  expr: |
    sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason{job="integrations/kubernetes/kube-state-metrics"}) > 0
  for: 1h
  labels:
    severity: warning
  annotations:
    description: Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container}} has been in waiting state for longer than 1 hour.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontainerwaiting
    summary: Pod container waiting longer than 1 hour
- record: ""
  alert: KubeDaemonSetNotScheduled
  expr: |
    kube_daemonset_status_desired_number_scheduled{job="integrations/kubernetes/kube-state-metrics"}
      -
    kube_daemonset_status_current_number_scheduled{job="integrations/kubernetes/kube-state-metrics"} > 0
  for: 10m
  labels:
    severity: warning
  annotations:
    description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.'
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled
    summary: DaemonSet pods are not scheduled.
- record: ""
  alert: KubeDaemonSetMisScheduled
  expr: |
    kube_daemonset_status_number_misscheduled{job="integrations/kubernetes/kube-state-metrics"} > 0
  for: 15m
  labels:
    severity: warning
  annotations:
    description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.'
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled
    summary: DaemonSet pods are misscheduled.
- record: ""
  alert: KubeJobCompletion
  expr: |
    kube_job_spec_completions{job="integrations/kubernetes/kube-state-metrics"} - kube_job_status_succeeded{job="integrations/kubernetes/kube-state-metrics"}  > 0
  for: 12h
  labels:
    severity: warning
  annotations:
    description: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than 12 hours to complete.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobcompletion
    summary: Job did not complete in time
- record: ""
  alert: KubeJobFailed
  expr: |
    kube_job_failed{job="integrations/kubernetes/kube-state-metrics"}  > 0
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed
    summary: Job failed to complete.
- record: ""
  alert: KubeHpaReplicasMismatch
  expr: |
    (kube_horizontalpodautoscaler_status_desired_replicas{job="integrations/kubernetes/kube-state-metrics"}
      !=
    kube_horizontalpodautoscaler_status_current_replicas{job="integrations/kubernetes/kube-state-metrics"})
      and
    (kube_horizontalpodautoscaler_status_current_replicas{job="integrations/kubernetes/kube-state-metrics"}
      >
    kube_horizontalpodautoscaler_spec_min_replicas{job="integrations/kubernetes/kube-state-metrics"})
      and
    (kube_horizontalpodautoscaler_status_current_replicas{job="integrations/kubernetes/kube-state-metrics"}
      <
    kube_horizontalpodautoscaler_spec_max_replicas{job="integrations/kubernetes/kube-state-metrics"})
      and
    changes(kube_horizontalpodautoscaler_status_current_replicas{job="integrations/kubernetes/kube-state-metrics"}[15m]) == 0
  for: 15m
  labels:
    severity: warning
  annotations:
    description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpareplicasmismatch
    summary: HPA has not matched descired number of replicas.
- record: ""
  alert: KubeHpaMaxedOut
  expr: |
    kube_horizontalpodautoscaler_status_current_replicas{job="integrations/kubernetes/kube-state-metrics"}
      ==
    kube_horizontalpodautoscaler_spec_max_replicas{job="integrations/kubernetes/kube-state-metrics"}
  for: 15m
  labels:
    severity: warning
  annotations:
    description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has been running at max replicas for longer than 15 minutes.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpamaxedout
    summary: HPA is running at max replicas
---
name: kubernetes-resources
interval: 0s
rules:
- record: ""
  alert: KubeCPUOvercommit
  expr: |
    sum(namespace_cpu:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource="cpu"}) - max(kube_node_status_allocatable{resource="cpu"})) > 0
    and
    (sum(kube_node_status_allocatable{resource="cpu"}) - max(kube_node_status_allocatable{resource="cpu"})) > 0
  for: 10m
  labels:
    severity: warning
  annotations:
    description: Cluster has overcommitted CPU resource requests for Pods by {{ $value }} CPU shares and cannot tolerate node failure.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
    summary: Cluster has overcommitted CPU resource requests.
- record: ""
  alert: KubeMemoryOvercommit
  expr: |
    sum(namespace_memory:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource="memory"}) - max(kube_node_status_allocatable{resource="memory"})) > 0
    and
    (sum(kube_node_status_allocatable{resource="memory"}) - max(kube_node_status_allocatable{resource="memory"})) > 0
  for: 10m
  labels:
    severity: warning
  annotations:
    description: Cluster has overcommitted memory resource requests for Pods by {{ $value }} bytes and cannot tolerate node failure.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryovercommit
    summary: Cluster has overcommitted memory resource requests.
- record: ""
  alert: KubeCPUQuotaOvercommit
  expr: |
    sum(kube_resourcequota{job="integrations/kubernetes/kube-state-metrics", type="hard", resource="cpu"})
      /
    sum(kube_node_status_allocatable{resource="cpu"})
      > 1.5
  for: 5m
  labels:
    severity: warning
  annotations:
    description: Cluster has overcommitted CPU resource requests for Namespaces.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuquotaovercommit
    summary: Cluster has overcommitted CPU resource requests.
- record: ""
  alert: KubeMemoryQuotaOvercommit
  expr: |
    sum(kube_resourcequota{job="integrations/kubernetes/kube-state-metrics", type="hard", resource="memory"})
      /
    sum(kube_node_status_allocatable{resource="memory",job="integrations/kubernetes/kube-state-metrics"})
      > 1.5
  for: 5m
  labels:
    severity: warning
  annotations:
    description: Cluster has overcommitted memory resource requests for Namespaces.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryquotaovercommit
    summary: Cluster has overcommitted memory resource requests.
- record: ""
  alert: KubeQuotaAlmostFull
  expr: |
    kube_resourcequota{job="integrations/kubernetes/kube-state-metrics", type="used"}
      / ignoring(instance, job, type)
    (kube_resourcequota{job="integrations/kubernetes/kube-state-metrics", type="hard"} > 0)
      > 0.9 < 1
  for: 15m
  labels:
    severity: info
  annotations:
    description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaalmostfull
    summary: Namespace quota is going to be full.
- record: ""
  alert: KubeQuotaFullyUsed
  expr: |
    kube_resourcequota{job="integrations/kubernetes/kube-state-metrics", type="used"}
      / ignoring(instance, job, type)
    (kube_resourcequota{job="integrations/kubernetes/kube-state-metrics", type="hard"} > 0)
      == 1
  for: 15m
  labels:
    severity: info
  annotations:
    description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotafullyused
    summary: Namespace quota is fully used.
- record: ""
  alert: KubeQuotaExceeded
  expr: |
    kube_resourcequota{job="integrations/kubernetes/kube-state-metrics", type="used"}
      / ignoring(instance, job, type)
    (kube_resourcequota{job="integrations/kubernetes/kube-state-metrics", type="hard"} > 0)
      > 1
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded
    summary: Namespace quota has exceeded the limits.
- record: ""
  alert: CPUThrottlingHigh
  expr: |
    sum(increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (container, pod, namespace)
      /
    sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace)
      > ( 25 / 100 )
  for: 15m
  labels:
    severity: info
  annotations:
    description: '{{ $value | humanizePercentage }} throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container }} in pod {{ $labels.pod }}.'
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-cputhrottlinghigh
    summary: Processes experience elevated CPU throttling.
---
name: kubernetes-system
interval: 0s
rules:
- record: ""
  alert: KubeVersionMismatch
  expr: |
    count(count by (git_version) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"git_version","$1","git_version","(v[0-9]*.[0-9]*).*"))) > 1
  for: 15m
  labels:
    severity: warning
  annotations:
    description: There are {{ $value }} different semantic versions of Kubernetes components running.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch
    summary: Different semantic versions of Kubernetes components running.
- record: ""
  alert: KubeClientErrors
  expr: |
    (sum(rate(rest_client_requests_total{code=~"5.."}[5m])) by (instance, job, namespace)
      /
    sum(rate(rest_client_requests_total[5m])) by (instance, job, namespace))
    > 0.01
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ $value | humanizePercentage }} errors.'
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors
    summary: Kubernetes API server client is experiencing errors.
---
name: kubernetes-system-kubelet
interval: 0s
rules:
- record: ""
  alert: KubeNodeNotReady
  expr: |
    kube_node_status_condition{job="integrations/kubernetes/kube-state-metrics",condition="Ready",status="true"} == 0
  for: 15m
  labels:
    severity: warning
  annotations:
    description: '{{ $labels.node }} has been unready for more than 15 minutes.'
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready
    summary: Node is not ready.
- record: ""
  alert: KubeNodeUnreachable
  expr: |
    (kube_node_spec_taint{job="integrations/kubernetes/kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job="integrations/kubernetes/kube-state-metrics",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn"}) == 1
  for: 15m
  labels:
    severity: warning
  annotations:
    description: '{{ $labels.node }} is unreachable and some workloads may be rescheduled.'
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodeunreachable
    summary: Node is unreachable.
- record: ""
  alert: KubeletTooManyPods
  expr: |
    count by(node) (
      (kube_pod_status_phase{job="integrations/kubernetes/kube-state-metrics",phase="Running"} == 1) * on(instance,pod,namespace,cluster) group_left(node) topk by(instance,pod,namespace,cluster) (1, kube_pod_info{job="integrations/kubernetes/kube-state-metrics"})
    )
    /
    max by(node) (
      kube_node_status_capacity{job="integrations/kubernetes/kube-state-metrics",resource="pods"} != 1
    ) > 0.95
  for: 15m
  labels:
    severity: info
  annotations:
    description: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage }} of its Pod capacity.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods
    summary: Kubelet is running at capacity.
- record: ""
  alert: KubeNodeReadinessFlapping
  expr: |
    sum(changes(kube_node_status_condition{status="true",condition="Ready"}[15m])) by (node) > 2
  for: 15m
  labels:
    severity: warning
  annotations:
    description: The readiness status of node {{ $labels.node }} has changed {{ $value }} times in the last 15 minutes.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodereadinessflapping
    summary: Node readiness status is flapping.
- record: ""
  alert: KubeletPlegDurationHigh
  expr: |
    node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile="0.99"} >= 10
  for: 5m
  labels:
    severity: warning
  annotations:
    description: The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration of {{ $value }} seconds on node {{ $labels.node }}.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletplegdurationhigh
    summary: Kubelet Pod Lifecycle Event Generator is taking too long to relist.
- record: ""
  alert: KubeletPodStartUpLatencyHigh
  expr: |
    histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job="integrations/kubernetes/kubelet"}[5m])) by (instance, le)) * on(instance) group_left(node) kubelet_node_name{job="integrations/kubernetes/kubelet"} > 60
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Kubelet Pod startup 99th percentile latency is {{ $value }} seconds on node {{ $labels.node }}.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletpodstartuplatencyhigh
    summary: Kubelet Pod startup latency is too high.
- record: ""
  alert: KubeletClientCertificateExpiration
  expr: |
    kubelet_certificate_manager_client_ttl_seconds < 604800
  for: 0s
  labels:
    severity: warning
  annotations:
    description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificateexpiration
    summary: Kubelet client certificate is about to expire.
- record: ""
  alert: KubeletClientCertificateExpiration
  expr: |
    kubelet_certificate_manager_client_ttl_seconds < 86400
  for: 0s
  labels:
    severity: critical
  annotations:
    description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificateexpiration
    summary: Kubelet client certificate is about to expire.
- record: ""
  alert: KubeletServerCertificateExpiration
  expr: |
    kubelet_certificate_manager_server_ttl_seconds < 604800
  for: 0s
  labels:
    severity: warning
  annotations:
    description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificateexpiration
    summary: Kubelet server certificate is about to expire.
- record: ""
  alert: KubeletServerCertificateExpiration
  expr: |
    kubelet_certificate_manager_server_ttl_seconds < 86400
  for: 0s
  labels:
    severity: critical
  annotations:
    description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificateexpiration
    summary: Kubelet server certificate is about to expire.
- record: ""
  alert: KubeletClientCertificateRenewalErrors
  expr: |
    increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Kubelet on node {{ $labels.node }} has failed to renew its client certificate ({{ $value | humanize }} errors in the last 5 minutes).
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificaterenewalerrors
    summary: Kubelet has failed to renew its client certificate.
- record: ""
  alert: KubeletServerCertificateRenewalErrors
  expr: |
    increase(kubelet_server_expiration_renew_errors[5m]) > 0
  for: 15m
  labels:
    severity: warning
  annotations:
    description: Kubelet on node {{ $labels.node }} has failed to renew its server certificate ({{ $value | humanize }} errors in the last 5 minutes).
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificaterenewalerrors
    summary: Kubelet has failed to renew its server certificate.
- record: ""
  alert: KubeletDown
  expr: |
    absent(up{job="integrations/kubernetes/kubelet"} == 1)
  for: 15m
  labels:
    severity: critical
  annotations:
    description: Kubelet has disappeared from Prometheus target discovery.
    runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown
    summary: Target disappeared from Prometheus target discovery.
---
name: k8s.rules
interval: 0s
rules:
- record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate
  alert: ""
  expr: |
    sum by (cluster, namespace, pod, container) (
      irate(container_cpu_usage_seconds_total{job="integrations/kubernetes/cadvisor", image!=""}[5m])
    ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
      1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
    )
  for: 0s
  labels: {}
  annotations: {}
- record: node_namespace_pod_container:container_memory_working_set_bytes
  alert: ""
  expr: |
    container_memory_working_set_bytes{job="integrations/kubernetes/cadvisor", image!=""}
    * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
      max by(namespace, pod, node) (kube_pod_info{node!=""})
    )
  for: 0s
  labels: {}
  annotations: {}
- record: node_namespace_pod_container:container_memory_rss
  alert: ""
  expr: |
    container_memory_rss{job="integrations/kubernetes/cadvisor", image!=""}
    * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
      max by(namespace, pod, node) (kube_pod_info{node!=""})
    )
  for: 0s
  labels: {}
  annotations: {}
- record: node_namespace_pod_container:container_memory_cache
  alert: ""
  expr: |
    container_memory_cache{job="integrations/kubernetes/cadvisor", image!=""}
    * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
      max by(namespace, pod, node) (kube_pod_info{node!=""})
    )
  for: 0s
  labels: {}
  annotations: {}
- record: node_namespace_pod_container:container_memory_swap
  alert: ""
  expr: |
    container_memory_swap{job="integrations/kubernetes/cadvisor", image!=""}
    * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
      max by(namespace, pod, node) (kube_pod_info{node!=""})
    )
  for: 0s
  labels: {}
  annotations: {}
- record: cluster:namespace:pod_memory:active:kube_pod_container_resource_requests
  alert: ""
  expr: |
    kube_pod_container_resource_requests{resource="memory",job="integrations/kubernetes/kube-state-metrics"}  * on (namespace, pod, cluster)
    group_left() max by (namespace, pod, cluster) (
      (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
    )
  for: 0s
  labels: {}
  annotations: {}
- record: namespace_memory:kube_pod_container_resource_requests:sum
  alert: ""
  expr: |
    sum by (namespace, cluster) (
        sum by (namespace, pod, cluster) (
            max by (namespace, pod, container, cluster) (
              kube_pod_container_resource_requests{resource="memory",job="integrations/kubernetes/kube-state-metrics"}
            ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
              kube_pod_status_phase{phase=~"Pending|Running"} == 1
            )
        )
    )
  for: 0s
  labels: {}
  annotations: {}
- record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests
  alert: ""
  expr: |
    kube_pod_container_resource_requests{resource="cpu",job="integrations/kubernetes/kube-state-metrics"}  * on (namespace, pod, cluster)
    group_left() max by (namespace, pod, cluster) (
      (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
    )
  for: 0s
  labels: {}
  annotations: {}
- record: namespace_cpu:kube_pod_container_resource_requests:sum
  alert: ""
  expr: |
    sum by (namespace, cluster) (
        sum by (namespace, pod, cluster) (
            max by (namespace, pod, container, cluster) (
              kube_pod_container_resource_requests{resource="cpu",job="integrations/kubernetes/kube-state-metrics"}
            ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
              kube_pod_status_phase{phase=~"Pending|Running"} == 1
            )
        )
    )
  for: 0s
  labels: {}
  annotations: {}
- record: cluster:namespace:pod_memory:active:kube_pod_container_resource_limits
  alert: ""
  expr: |
    kube_pod_container_resource_limits{resource="memory",job="integrations/kubernetes/kube-state-metrics"}  * on (namespace, pod, cluster)
    group_left() max by (namespace, pod, cluster) (
      (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
    )
  for: 0s
  labels: {}
  annotations: {}
- record: namespace_memory:kube_pod_container_resource_limits:sum
  alert: ""
  expr: |
    sum by (namespace, cluster) (
        sum by (namespace, pod, cluster) (
            max by (namespace, pod, container, cluster) (
              kube_pod_container_resource_limits{resource="memory",job="integrations/kubernetes/kube-state-metrics"}
            ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
              kube_pod_status_phase{phase=~"Pending|Running"} == 1
            )
        )
    )
  for: 0s
  labels: {}
  annotations: {}
- record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_limits
  alert: ""
  expr: |
    kube_pod_container_resource_limits{resource="cpu",job="integrations/kubernetes/kube-state-metrics"}  * on (namespace, pod, cluster)
    group_left() max by (namespace, pod, cluster) (
     (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
     )
  for: 0s
  labels: {}
  annotations: {}
- record: namespace_cpu:kube_pod_container_resource_limits:sum
  alert: ""
  expr: |
    sum by (namespace, cluster) (
        sum by (namespace, pod, cluster) (
            max by (namespace, pod, container, cluster) (
              kube_pod_container_resource_limits{resource="cpu",job="integrations/kubernetes/kube-state-metrics"}
            ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
              kube_pod_status_phase{phase=~"Pending|Running"} == 1
            )
        )
    )
  for: 0s
  labels: {}
  annotations: {}
- record: namespace_workload_pod:kube_pod_owner:relabel
  alert: ""
  expr: |
    max by (cluster, namespace, workload, pod) (
      label_replace(
        label_replace(
          kube_pod_owner{job="integrations/kubernetes/kube-state-metrics", owner_kind="ReplicaSet"},
          "replicaset", "$1", "owner_name", "(.*)"
        ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (
          1, max by (replicaset, namespace, owner_name) (
            kube_replicaset_owner{job="integrations/kubernetes/kube-state-metrics"}
          )
        ),
        "workload", "$1", "owner_name", "(.*)"
      )
    )
  for: 0s
  labels:
    workload_type: deployment
  annotations: {}
- record: namespace_workload_pod:kube_pod_owner:relabel
  alert: ""
  expr: |
    max by (cluster, namespace, workload, pod) (
      label_replace(
        kube_pod_owner{job="integrations/kubernetes/kube-state-metrics", owner_kind="DaemonSet"},
        "workload", "$1", "owner_name", "(.*)"
      )
    )
  for: 0s
  labels:
    workload_type: daemonset
  annotations: {}
- record: namespace_workload_pod:kube_pod_owner:relabel
  alert: ""
  expr: |
    max by (cluster, namespace, workload, pod) (
      label_replace(
        kube_pod_owner{job="integrations/kubernetes/kube-state-metrics", owner_kind="StatefulSet"},
        "workload", "$1", "owner_name", "(.*)"
      )
    )
  for: 0s
  labels:
    workload_type: statefulset
  annotations: {}